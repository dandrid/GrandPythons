{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to download the Data Set from Google Drive\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAVDESS_original.zip https://drive.google.com/open?id=1WyJsDuxJlUObBCFrNZLAXM2w4-sp0CxN\n",
    "# file_id = '1WyJsDuxJlUObBCFrNZLAXM2w4-sp0CxN'\n",
    "\n",
    "# RAVDESS_trimmed.zip https://drive.google.com/open?id=1pFum_YGf2C82HJvMwt0gi8apj6PJLi0s\n",
    "#file_id = '1pFum_YGf2C82HJvMwt0gi8apj6PJLi0s'\n",
    "\n",
    "# RAVDESS_enriched.zip https://drive.google.com/open?id=1LG42oQTSs6HWMLsdqhFKbADA2wi8234_\n",
    "# file_id = '1LG42oQTSs6HWMLsdqhFKbADA2wi8234_'\n",
    "\n",
    "# RAVDESS_spectogram.zip https://drive.google.com/open?id=1jDb2GDnapxx-5bhRR4rudVLxd4ajrpF-\n",
    "# file_id = '1jDb2GDnapxx-5bhRR4rudVLxd4ajrpF-'\n",
    "\n",
    "# RAVDESS_train.zip https://drive.google.com/open?id=1jDb2GDnapxx-5bhRR4rudVLxd4ajrpF-\n",
    "file_id = '1N0zUWDYfZR4xUDQVNKJEnO9bFL4Y1NRM'\n",
    "\n",
    "destination = 'RAVDESS.zip'\n",
    "\n",
    "if not os.path.exists(destination):\n",
    "    download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -n RAVDESS.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls RAVDESS/ -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from scipy.signal import spectrogram\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "import gc\n",
    "from IPython.display import Image, display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_data(self, path):\n",
    "    numbers = re.findall(r'\\d+', path) # numbers in the name of the audio file\n",
    "    # spectogram = Image.open(spectogram_path) # consumes too much memory\n",
    "    return [\n",
    "        self.emotions[numbers[2]],\n",
    "        self.emotion_intensities[numbers[3]],\n",
    "        self.statements[numbers[4]],\n",
    "        self.repetitions[int(numbers[5])-1],\n",
    "        numbers[6], \n",
    "        self.actors[numbers[6]], \n",
    "        path\n",
    "    ]\n",
    "\n",
    "\n",
    "# Creates the Data Frame for the RAVDESS\n",
    "def create_dataframe(self):\n",
    "    print('Create dataframe')\n",
    "    data = []\n",
    "    specograms_paths = self.get_split_image_paths()\n",
    "    for specograms_path in specograms_paths:\n",
    "        data.append(self.name_to_data(specograms_path))\n",
    "\n",
    "    df = pd.DataFrame(  # contruct DataFrame from data\n",
    "        { \n",
    "            'emotion'           : pd.Categorical([row[0] for row in data]),\n",
    "            'emotion_intensity' : pd.Categorical([row[1] for row in data]),\n",
    "            'statement'         : pd.Categorical([row[2] for row in data]),\n",
    "            'repetition'        : pd.Categorical([row[3] for row in data]),\n",
    "            'actor'             : pd.Categorical([row[4] for row in data]),\n",
    "            'actor_gender'      : pd.Categorical([row[5] for row in data]),\n",
    "            'image'             : pd.Categorical([row[6] for row in data])\n",
    "        })\n",
    "\n",
    "    # one-hot encode columns\n",
    "    df = pd.get_dummies(df, columns=[\"emotion\", \"emotion_intensity\", \"statement\", \"repetition\", \"actor\", \"actor_gender\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height=299\n",
    "img_width=299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# előtanított modell betöltése, a fully-connected rétegek nélkül\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "# az utolsó konvolúciós réteg utána egy global average pooling réteget teszünk, ez rögtön \"lapítja\" (flatten) a 2D konvolúciót\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# ezután hozzáadunk egy előrecsatolt réteget ReLU aktivációs függvénnyel\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# és végül egy kimenete lesz a hálónak - a \"binary_crossentropy\" költségfüggvénynek erre van szüksége\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# a model létrehozása\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# lefordítjuk a modelt (fontos, hogy ezt a rétegek befagyasztása után csináljuk\"\n",
    "# mivel két osztályunk van, ezért bináris keresztentrópia költségfüggvényt használunk\n",
    "model.compile(optimizer='adam', metrics=['accuracy'],loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kép felkészítése a betöltésre és adatdúsításra\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(img_height, img_width), batch_size=20, class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, target_size=(img_height, img_width), batch_size=20, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ez a függvény egyszerre végzi az adatdúsítást és a háló tanítását\n",
    "model.fit_generator(train_generator,steps_per_epoch=200,validation_data=validation_generator,validation_steps=10,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:172]:\n",
    "       layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "       layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ez után újra le kell fordítanunk a hálót, hogy most már az Inception V3 felsőbb rétegei tanuljanak\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), metrics=['accuracy'], loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator,steps_per_epoch=200,validation_data=validation_generator,validation_steps=10,epochs=3)\n",
    "print(\"Tanítás vége.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
